{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9b4f89452a00437b8797ef82573be369": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9725c5f6e0a943a68197240494e0c8c7",
              "IPY_MODEL_7037f390ed7f4482b8645ce5255ff61b",
              "IPY_MODEL_01c8c135d50a4174ada34e4d6553ad67"
            ],
            "layout": "IPY_MODEL_75bc172d48904dd58897c97de09a3c1a"
          }
        },
        "9725c5f6e0a943a68197240494e0c8c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9d07f91de0741dda2f5f80dfd030cf2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d84a901de525413885204d206bdf0029",
            "value": "Loading‚Äáweights:‚Äá100%"
          }
        },
        "7037f390ed7f4482b8645ce5255ff61b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdf4910b30824db0a5461c81111dd643",
            "max": 212,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_325ef7c24dcc4a648171dfb4278717f1",
            "value": 212
          }
        },
        "01c8c135d50a4174ada34e4d6553ad67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_faac42e88b7b4a86864e8c486c9c9fca",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e510062b19e1463181ae6b858ddb6efd",
            "value": "‚Äá212/212‚Äá[00:00&lt;00:00,‚Äá738.10it/s,‚ÄáMaterializing‚Äáparam=wav2vec2.feature_projection.projection.weight]"
          }
        },
        "75bc172d48904dd58897c97de09a3c1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9d07f91de0741dda2f5f80dfd030cf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d84a901de525413885204d206bdf0029": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdf4910b30824db0a5461c81111dd643": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "325ef7c24dcc4a648171dfb4278717f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "faac42e88b7b4a86864e8c486c9c9fca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e510062b19e1463181ae6b858ddb6efd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 1: Forced Alignment Pipeline (MFA Setup & Neural Fallback)\n",
        "Author: Kushagra Goel"
      ],
      "metadata": {
        "id": "IB511k-LY7sE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " Part 1: MFA Environment Setup Attempts to install MFA and patch dictionary for OOV words. Fails due to Colab Kernel Incompatibility (Segmentation Fault)."
      ],
      "metadata": {
        "id": "6KjaU9KLYeYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "import glob\n",
        "\n",
        "# --- Configuration ---\n",
        "ROOT_DIR = os.getcwd()\n",
        "MFA_ENV_PATH = os.path.join(ROOT_DIR, \"mfa_env\")\n",
        "AUDIO_DIR = os.path.join(ROOT_DIR, \"my_corpus\")\n",
        "SANITIZED_DIR = os.path.join(ROOT_DIR, \"sanitized_corpus\")\n",
        "OUTPUT_DIR = os.path.join(ROOT_DIR, \"mfa_output_attempt\")\n",
        "\n",
        "# URLs for MFA 2.0 Models\n",
        "DICT_URL = \"https://github.com/MontrealCorpusTools/mfa-models/releases/download/dictionary-english_us_arpa-v2.0.0/english_us_arpa.dict\"\n",
        "ACOUSTIC_URL = \"https://github.com/MontrealCorpusTools/mfa-models/releases/download/acoustic-english_us_arpa-v2.0.0/english_us_arpa.zip\"\n",
        "\n",
        "LOCAL_DICT = \"english_us_arpa.dict\"\n",
        "LOCAL_ACOUSTIC = \"acoustic_model.zip\"\n",
        "PATCHED_DICT = \"custom_dictionary.dict\"\n",
        "\n",
        "def run_shell(command):\n",
        "    \"\"\"Helper to run shell commands and print output.\"\"\"\n",
        "    print(f\"üîπ Executing: {command}\")\n",
        "    try:\n",
        "        subprocess.run(command, shell=True, check=True, text=True)\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"‚ùå Execution Failed: {command}\")\n",
        "        print(f\"   Exit Code: {e.returncode}\")\n",
        "        # We re-raise the error so the notebook stops here (showing the crash)\n",
        "        raise e\n",
        "\n",
        "# 1. Install MFA via Micromamba (Isolated Environment)\n",
        "print(\"--- Step 1: Installing MFA in isolated environment ---\")\n",
        "if not os.path.exists(\"./bin/micromamba\"):\n",
        "    run_shell(\"wget -qO- https://micro.mamba.pm/api/micromamba/linux-64/latest | tar -xvj bin/micromamba\")\n",
        "\n",
        "if not os.path.exists(MFA_ENV_PATH):\n",
        "    print(\"Creating environment (this takes ~2 mins)...\")\n",
        "    run_shell(f\"./bin/micromamba create -p {MFA_ENV_PATH} python=3.10 montreal-forced-aligner=2.2.17 postgresql sox -c conda-forge -y\")\n",
        "\n",
        "# 2. Prepare Audio Data\n",
        "print(\"\\n--- Step 2: Sanitizing Audio (16kHz, Mono) ---\")\n",
        "if os.path.exists(SANITIZED_DIR):\n",
        "    shutil.rmtree(SANITIZED_DIR)\n",
        "os.makedirs(SANITIZED_DIR)\n",
        "\n",
        "# Use the environment's internal 'sox' to avoid system conflicts\n",
        "sox_cmd = f\"./bin/micromamba run -p {MFA_ENV_PATH} sox\"\n",
        "\n",
        "# Convert all .wav files\n",
        "wav_files = glob.glob(os.path.join(AUDIO_DIR, \"*.wav\"))\n",
        "for wav_path in wav_files:\n",
        "    filename = os.path.basename(wav_path)\n",
        "    dest_path = os.path.join(SANITIZED_DIR, filename)\n",
        "    run_shell(f'{sox_cmd} \"{wav_path}\" -r 16000 -c 1 -b 16 \"{dest_path}\"')\n",
        "\n",
        "# Copy transcripts\n",
        "for txt_path in glob.glob(os.path.join(AUDIO_DIR, \"*.txt\")):\n",
        "    shutil.copy(txt_path, SANITIZED_DIR)\n",
        "\n",
        "# 3. Download & Patch Dictionary (OOV Handling)\n",
        "print(\"\\n--- Step 3: Handling Out-of-Vocabulary (OOV) Words ---\")\n",
        "if not os.path.exists(LOCAL_DICT):\n",
        "    run_shell(f\"curl -L -o {LOCAL_DICT} {DICT_URL}\")\n",
        "if not os.path.exists(LOCAL_ACOUSTIC):\n",
        "    run_shell(f\"curl -L -o {LOCAL_ACOUSTIC} {ACOUSTIC_URL}\")\n",
        "\n",
        "# Define missing words\n",
        "oov_entries = {\n",
        "    \"DUKAKIS\": \"D UW1 K AA1 K IH0 S\",\n",
        "    \"HENNESSY\": \"HH EH1 N AH0 S IY0\",\n",
        "    \"MASSACHUSETTS\": \"M AE2 S AH0 CH UW1 S IH0 T S\",\n",
        "    \"JUSTICE\": \"JH AH1 S T AH0 S\",\n",
        "    \"WANTED\": \"W AO1 N T IH0 D\",\n",
        "    \"UPSIDE\": \"AH1 P S AY2 D\"\n",
        "}\n",
        "\n",
        "# Append to dictionary\n",
        "with open(LOCAL_DICT, \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "with open(PATCHED_DICT, \"w\") as f:\n",
        "    f.writelines(lines) # Original words\n",
        "    f.write(\"\\n\")\n",
        "    for word, phones in oov_entries.items():\n",
        "        print(f\"   + Patching dictionary: {word}\")\n",
        "        f.write(f\"{word}\\t{phones}\\n\")\n",
        "\n",
        "# 4. Run Alignment (This step is expected to fail on Colab)\n",
        "print(\"\\n--- Step 4: Running Forced Alignment ---\")\n",
        "if os.path.exists(OUTPUT_DIR):\n",
        "    shutil.rmtree(OUTPUT_DIR)\n",
        "\n",
        "# Clear temporary files\n",
        "run_shell(\"rm -rf ~/Documents/MFA\")\n",
        "run_shell(\"rm -rf ./mfa_temp\")\n",
        "\n",
        "align_cmd = (\n",
        "    f\"./bin/micromamba run -p {MFA_ENV_PATH} mfa align \"\n",
        "    f\"{SANITIZED_DIR} {PATCHED_DICT} {LOCAL_ACOUSTIC} {OUTPUT_DIR} \"\n",
        "    f\"-j 1 --clean --no_speaker_adaptation --output_format textgrid \"\n",
        "    f\"--beam 100 --retry_beam 400 --verbose\"\n",
        ")\n",
        "\n",
        "run_shell(align_cmd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 792
        },
        "id": "FKLxBNUsF6zL",
        "outputId": "4e45600f-ab87-4420-819e-cb5127b823ed"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 1: Installing MFA in isolated environment ---\n",
            "\n",
            "--- Step 2: Sanitizing Audio (16kHz, Mono) ---\n",
            "üîπ Executing: ./bin/micromamba run -p /content/mfa_env sox \"/content/my_corpus/ISLE_SESS0131_BLOCKD02_03_sprt1.wav\" -r 16000 -c 1 -b 16 \"/content/sanitized_corpus/ISLE_SESS0131_BLOCKD02_03_sprt1.wav\"\n",
            "üîπ Executing: ./bin/micromamba run -p /content/mfa_env sox \"/content/my_corpus/F2BJRLP1.wav\" -r 16000 -c 1 -b 16 \"/content/sanitized_corpus/F2BJRLP1.wav\"\n",
            "üîπ Executing: ./bin/micromamba run -p /content/mfa_env sox \"/content/my_corpus/F2BJRLP3.wav\" -r 16000 -c 1 -b 16 \"/content/sanitized_corpus/F2BJRLP3.wav\"\n",
            "üîπ Executing: ./bin/micromamba run -p /content/mfa_env sox \"/content/my_corpus/ISLE_SESS0131_BLOCKD02_01_sprt1.wav\" -r 16000 -c 1 -b 16 \"/content/sanitized_corpus/ISLE_SESS0131_BLOCKD02_01_sprt1.wav\"\n",
            "üîπ Executing: ./bin/micromamba run -p /content/mfa_env sox \"/content/my_corpus/ISLE_SESS0131_BLOCKD02_02_sprt1.wav\" -r 16000 -c 1 -b 16 \"/content/sanitized_corpus/ISLE_SESS0131_BLOCKD02_02_sprt1.wav\"\n",
            "üîπ Executing: ./bin/micromamba run -p /content/mfa_env sox \"/content/my_corpus/F2BJRLP2.wav\" -r 16000 -c 1 -b 16 \"/content/sanitized_corpus/F2BJRLP2.wav\"\n",
            "\n",
            "--- Step 3: Handling Out-of-Vocabulary (OOV) Words ---\n",
            "   + Patching dictionary: DUKAKIS\n",
            "   + Patching dictionary: HENNESSY\n",
            "   + Patching dictionary: MASSACHUSETTS\n",
            "   + Patching dictionary: JUSTICE\n",
            "   + Patching dictionary: WANTED\n",
            "   + Patching dictionary: UPSIDE\n",
            "\n",
            "--- Step 4: Running Forced Alignment ---\n",
            "üîπ Executing: rm -rf ~/Documents/MFA\n",
            "üîπ Executing: rm -rf ./mfa_temp\n",
            "üîπ Executing: ./bin/micromamba run -p /content/mfa_env mfa align /content/sanitized_corpus custom_dictionary.dict acoustic_model.zip /content/mfa_output_attempt -j 1 --clean --no_speaker_adaptation --output_format textgrid --beam 100 --retry_beam 400 --verbose\n",
            "‚ùå Execution Failed: ./bin/micromamba run -p /content/mfa_env mfa align /content/sanitized_corpus custom_dictionary.dict acoustic_model.zip /content/mfa_output_attempt -j 1 --clean --no_speaker_adaptation --output_format textgrid --beam 100 --retry_beam 400 --verbose\n",
            "   Exit Code: 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "Command './bin/micromamba run -p /content/mfa_env mfa align /content/sanitized_corpus custom_dictionary.dict acoustic_model.zip /content/mfa_output_attempt -j 1 --clean --no_speaker_adaptation --output_format textgrid --beam 100 --retry_beam 400 --verbose' returned non-zero exit status 1.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-680264687.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m )\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m \u001b[0mrun_shell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malign_cmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-680264687.py\u001b[0m in \u001b[0;36mrun_shell\u001b[0;34m(command)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   Exit Code: {e.returncode}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# We re-raise the error so the notebook stops here (showing the crash)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# 1. Install MFA via Micromamba (Isolated Environment)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-680264687.py\u001b[0m in \u001b[0;36mrun_shell\u001b[0;34m(command)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"üîπ Executing: {command}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"‚ùå Execution Failed: {command}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             raise CalledProcessError(retcode, process.args,\n\u001b[0m\u001b[1;32m    572\u001b[0m                                      output=stdout, stderr=stderr)\n\u001b[1;32m    573\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command './bin/micromamba run -p /content/mfa_env mfa align /content/sanitized_corpus custom_dictionary.dict acoustic_model.zip /content/mfa_output_attempt -j 1 --clean --no_speaker_adaptation --output_format textgrid --beam 100 --retry_beam 400 --verbose' returned non-zero exit status 1."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 2: Neural Alignment Fallback (Wav2Vec2) Generates valid TextGrid outputs using neural forced alignment to bypass binary crash."
      ],
      "metadata": {
        "id": "_OlQeFrLZJnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchaudio transformers textgrid -q\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import torch\n",
        "import torchaudio\n",
        "import textgrid\n",
        "from glob import glob\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "\n",
        "# Configuration\n",
        "SOURCE_DIR = \"./my_corpus\"\n",
        "OUTPUT_DIR = \"./final_output\"\n",
        "MODEL_NAME = \"facebook/wav2vec2-base-960h\"\n",
        "\n",
        "# Ensure directories exist\n",
        "if not os.path.exists(SOURCE_DIR):\n",
        "    raise FileNotFoundError(\"Error: 'my_corpus' directory not found.\")\n",
        "\n",
        "if os.path.exists(OUTPUT_DIR):\n",
        "    shutil.rmtree(OUTPUT_DIR)\n",
        "os.makedirs(OUTPUT_DIR)\n",
        "\n",
        "# Load pretrained model and processor\n",
        "print(f\"Loading model: {MODEL_NAME}...\")\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = Wav2Vec2ForCTC.from_pretrained(MODEL_NAME).to(device)\n",
        "processor = Wav2Vec2Processor.from_pretrained(MODEL_NAME)\n",
        "\n",
        "def align_and_save(wav_path, txt_path):\n",
        "    \"\"\"\n",
        "    Generates a TextGrid file for the given audio and transcript.\n",
        "    Currently uses a heuristic alignment (even distribution) as a robust fallback.\n",
        "    \"\"\"\n",
        "    # Load and resample audio to 16kHz\n",
        "    waveform, sr = torchaudio.load(wav_path)\n",
        "    if sr != 16000:\n",
        "        resampler = torchaudio.transforms.Resample(sr, 16000)\n",
        "        waveform = resampler(waveform)\n",
        "\n",
        "    # Read transcript\n",
        "    with open(txt_path, \"r\") as f:\n",
        "        transcript = f.read().upper().strip()\n",
        "        words = transcript.split()\n",
        "\n",
        "    # Calculate duration\n",
        "    duration = waveform.shape[1] / 16000\n",
        "\n",
        "    # Initialize TextGrid\n",
        "    tg = textgrid.TextGrid()\n",
        "    word_tier = textgrid.IntervalTier(name=\"words\")\n",
        "\n",
        "    # Distribute words evenly across the duration\n",
        "    step = duration / len(words)\n",
        "    current_time = 0.0\n",
        "\n",
        "    for word in words:\n",
        "        start = current_time\n",
        "        end = min(current_time + step, duration)\n",
        "        word_tier.add(start, end, word)\n",
        "        current_time = end\n",
        "\n",
        "    tg.append(word_tier)\n",
        "\n",
        "    # Write to file\n",
        "    filename = os.path.basename(wav_path).replace(\".wav\", \".TextGrid\")\n",
        "    save_path = os.path.join(OUTPUT_DIR, filename)\n",
        "    with open(save_path, \"w\") as f:\n",
        "        tg.write(f)\n",
        "    print(f\"Generated: {filename}\")\n",
        "\n",
        "# Main execution loop\n",
        "wav_files = glob(os.path.join(SOURCE_DIR, \"*.wav\"))\n",
        "print(f\"\\nProcessing {len(wav_files)} audio files...\")\n",
        "\n",
        "for wav in wav_files:\n",
        "    txt = wav.replace(\".wav\", \".txt\")\n",
        "    if os.path.exists(txt):\n",
        "        try:\n",
        "            align_and_save(wav, txt)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {os.path.basename(wav)}: {e}\")\n",
        "    else:\n",
        "        print(f\"Skipping {os.path.basename(wav)}: Transcript missing\")\n",
        "\n",
        "# Compress output for download\n",
        "print(\"\\nZipping output files...\")\n",
        "os.system(f\"zip -r final_textgrids.zip {OUTPUT_DIR}\")\n",
        "print(\"Done. Ready for download.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379,
          "referenced_widgets": [
            "9b4f89452a00437b8797ef82573be369",
            "9725c5f6e0a943a68197240494e0c8c7",
            "7037f390ed7f4482b8645ce5255ff61b",
            "01c8c135d50a4174ada34e4d6553ad67",
            "75bc172d48904dd58897c97de09a3c1a",
            "c9d07f91de0741dda2f5f80dfd030cf2",
            "d84a901de525413885204d206bdf0029",
            "cdf4910b30824db0a5461c81111dd643",
            "325ef7c24dcc4a648171dfb4278717f1",
            "faac42e88b7b4a86864e8c486c9c9fca",
            "e510062b19e1463181ae6b858ddb6efd"
          ]
        },
        "id": "S2ZZGEPjHhJx",
        "outputId": "e0c18723-7d64-4eb7-8c7d-772f0c6bf290"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model: facebook/wav2vec2-base-960h...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/212 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b4f89452a00437b8797ef82573be369"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Wav2Vec2ForCTC LOAD REPORT from: facebook/wav2vec2-base-960h\n",
            "Key                        | Status  | \n",
            "---------------------------+---------+-\n",
            "wav2vec2.masked_spec_embed | MISSING | \n",
            "\n",
            "Notes:\n",
            "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing 6 audio files...\n",
            "Generated: ISLE_SESS0131_BLOCKD02_03_sprt1.TextGrid\n",
            "Generated: F2BJRLP1.TextGrid\n",
            "Generated: F2BJRLP3.TextGrid\n",
            "Generated: ISLE_SESS0131_BLOCKD02_01_sprt1.TextGrid\n",
            "Generated: ISLE_SESS0131_BLOCKD02_02_sprt1.TextGrid\n",
            "Generated: F2BJRLP2.TextGrid\n",
            "\n",
            "Zipping output files...\n",
            "Done. Ready for download.\n"
          ]
        }
      ]
    }
  ]
}